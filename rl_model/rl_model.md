
## *RL êµ¬í˜„

- matrix ì…ë ¥ ë°›ì•„ ë‹¤ìŒ ì¢Œí‘œ ì¶”ì¶œ
	- agent : ë‘ëŠ” ë†ˆ 
	- environment : ë°”ë‘‘íŒ matrix
	- state : ë°”ë‘‘íŒ matrix ì „ì²´
	- reward : í• ì¸ìœ¨ì€ ì–´ë–»ê²Œ?
	- action : discrete / ì¢Œí‘œì— ë‘ê¸°
	- episode ëŠ” 5ê°œ ì™„ì„± ì‹œ
	- exploration <> exploitation
	- value based >> policy based
	- temporal difference ë¡œ value ì—…ë°ì´íŠ¸
- ë³´ìƒ
	- 2ê°œ ë§Œë“¤ë©´ +1
	- 3ê°œ ë§Œë“¤ë©´ +2
	- 4ê°œ ë§Œë“¤ë©´ +3
	- 5ê°œ ë§Œë“¤ë©´ +100
	- ìƒëŒ€ê°€ 2ê°œ ë§Œë“¤ë©´ -1
	- ìƒëŒ€ê°€ 3ê°œ ë§Œë“¤ë©´ -2
	- ìƒëŒ€ê°€ 4ê°œ ë§Œë“¤ë©´ -3
	- ìƒëŒ€ê°€ 5ê°œ ë§Œë“¤ë©´ -100

ìƒëŒ€ë‚˜ ë³¸ì¸ì´ 5ê°œ ë§Œë“¤ë©´ ì¢…ë£Œ / 30ìˆ˜ ì´ìƒ ì¢…ë£Œ
í•™ìŠµ ì‹œ ê° ìƒ‰ìƒì˜ ëŒì˜ ë³´ìƒì„ í•¨ê»˜ ê³„ì‚°ì„ ê³ ë ¤
ëª¨ë¸ì€ dqnìœ¼ë¡œ êµ¬ìƒ

##### Qê³„ì‚°ì‹
![[q_.jpg]](../image/q_.jpg)


##### Q table
ìƒíƒœ í‘ëŒ (ì•¡ì…˜ì—´ ê° ì¢Œí‘œë“¤)
ìƒíƒœ ë°±ëŒ (ì•¡ì…˜ì—´ ê° ì¢Œí‘œë“¤)

| step | agent | state | reward | epsilon | lr  | gamma | action_coor_00 | action_coor_01 | action_coor_02 | action_coor_03 | action_coor_04 | action_coor_05 |
| ---- | ----- | ----- | ------ | ------- | --- | ----- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- |
| 0    | white | alive | 0      | 1       | 0.1 | 0.99  | 0              | 0              | 0              | 0              | 0              | 0              |
| 1    | white | alive | 0      | 0.99    | 0.1 | 0.99  | 0              | 0              | 0              | 5              | 0              | 0              |
| 2    | white | die   | 0      | 0.99    | 0.1 | 0.99  | 0              | 0              | 0              | 0              | 0              | 0              |
|      |       |       |        |         |     |       |                |                |                |                |                |                |

#### library
gymnasium  
stable baseline3  


#### í™˜ê²½êµ¬ì„±
```
dqnìœ¼ë¡œ êµ¬í˜„ ì‹œ ì´ë¯¸ ë‘” ìë¦¬ë¥¼ ë‹¤ì‹œ ë‘˜ ê²½ìš° íŒ¨ë„í‹°ë¡œ ê²Œì„ì´ ì¢…ë£Œë¨
ì´ë¯¸ ë‘” ìë¦¬ë¥¼ ë‹¤ì‹œ ë‘ì§€ ì•Šê¸° ìœ„í•´ ë§ˆì´ë„ˆìŠ¤ ë³´ìƒì„ ì ìš©í•˜ì˜€ì§€ë§Œ, íƒìƒ‰ ì‹œ ë§¤ ìŠ¤íƒ­ë§ˆë‹¤ ëœë¤ìœ¼ë¡œ ì¢Œí‘œê°€ ìƒì„±ë˜ì–´ ë§ˆì´ë„ˆìŠ¤ ë³´ìƒìœ¼ë¡œ ì¸í•œ í•™ìŠµì´ ì§„í–‰ë˜ì§€ ì•ŠìŒ > ppoë¡œ ë³€ê²½í•˜ì—¬ ì•¡ì…˜ ë§ˆìŠ¤í¬ ì ìš©
```

ìµœëŒ€ í„´ ì œí•œ : 30ìˆ˜  
í˜„ì¬ í„´ ì €ì¥  
ìƒëŒ€í¸ ëª¨ë¸ì˜ ì—°ì†ëœ ëŒ ìˆ˜ëŠ” ë§ˆì´ë„ˆìŠ¤ ë³´ìƒ ì ìš©  
ìŠ¤íƒ­ : ì¡°ê¸° ì¢…ë£Œê°€ ë˜ì§€ ì•Šì„ ê²½ìš° ì•„ë˜ì™€ ê°™ì´ ë³´ìƒ ì ìš©
ë¶ˆí•„ìš”í•œ ìë¦¬ì— ë‘ì§€ ì•Šê¸° ìœ„í•´ í„´ìˆ˜ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ ë§ˆì´ë„ˆìŠ¤ ë³´ìƒ ì ìš©
```
total_reward = agent_reward - opp_reward - self.current_turn*0.01
```

í‰ê°€ :
5ëŒì˜ ë³´ìƒì´ 1.0ì¼ ê²½ìš° 5ê°œ ëŒì„ ë§Œë“¤ì§€ ì•Šê³  30í„´ ì „ê¹Œì§€ 4ê°œ êµ¬ì„±ì„ ìµœëŒ€í•œ ë§ì´ ë§Œë“¤ë ¤ëŠ” í–‰íƒœë¥¼ ë³´ì„ > 5ì˜ ë³´ìƒì„ 100.0ìœ¼ë¡œ ì˜¬ë ¤ì„œ í•™ìŠµ ì§„í–‰  
```
def _evaluate_board(self, player):
	chain, check_win = self._max_consecutive(player)
	reward = {2: 0.1, 3: 0.3, 4: 0.7, 5: 100.0}.get(chain, 0.0)
	return reward, check_win
```


#### ì •ì±…
ê¸°ì¡´ ëª¨ë¸ì— ì•¡ì…˜ ë§ˆìŠ¤í¬ ì ìš© ë° ë§ˆìŠ¤í¬ ë¡œì§“ ì ìš©
```
class MaskedCategorical(Categorical):
    def __init__(self, logits, mask):
        logits = logits.clone()
        logits[~mask] = -1e8  # ë§¤ìš° ì‘ì€ ê°’ìœ¼ë¡œ ì„¤ì •í•´ì„œ softmaxì—ì„œ ë¬´ì‹œ
        super().__init__(logits=logits)
```

#### ê°•í™” í•™ìŠµ
í•™ìŠµ ì‹œ ì¸í„°ë²Œ ë§ˆë‹¤ ìƒëŒ€ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ ìƒëŒ€ë¥¼ ì´ê¸°ê¸° ìœ„í•œ ê°•í™” í•™ìŠµì„ ì§„í–‰  
ì¸í„°ë²Œ í…€ì´ ë„ˆë¬´ í¬ë©´ ìƒëŒ€ë³´ë‹¤ ë©”ì¸ ëª¨ë¸ì´ ë„ˆë¬´ ì˜í•´ í•™ìŠµì´ ì˜ì•ˆë¨

```
# í•™ìŠµ ë£¨í”„
for step in range(0, total_timesteps, update_interval):
    print(f"â–¶ Learning step {step} ~ {step + update_interval}")

    # ì£¼ì¸ê³µ ëª¨ë¸ í•™ìŠµ
    main_model.learn(
        total_timesteps=update_interval,
        reset_num_timesteps=False,
        callback=WinnerLoggingCallback()
    )

    # ğŸ†• opponent ëª¨ë¸ ì—…ë°ì´íŠ¸
    print("ğŸ” Updating opponent model...")
    main_model.save("./rl_model/temp_main_model_ppo.zip")
    print('saved')
    updated_opponent_model = PPO.load("./rl_model/temp_main_model_ppo.zip")


    for env_idx in range(vec_env.num_envs):
        raw_env = vec_env.envs[env_idx].unwrapped
        raw_env.set_opponent_model(updated_opponent_model)
```

#### valid
```
[[0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 1 0 0 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]]

.............

[[0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0 0]
 [0 0 0 2 0 2 0 0 0 0 0 0 0]
 [0 0 0 0 1 1 2 0 0 0 0 0 0]
 [0 0 0 0 2 1 0 0 0 0 0 0 0]
 [0 0 2 0 0 0 1 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]]
.............

[[0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0 0]
 [0 0 0 2 2 2 0 0 0 0 0 0 0]
 [0 2 2 1 1 1 2 0 0 0 0 0 0]
 [0 0 0 2 2 1 0 0 0 0 0 0 0]
 [0 0 2 1 1 1 1 0 0 0 0 0 0]
 [0 0 0 0 0 1 0 2 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]]

[[0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0 0]
 [0 0 0 2 2 2 0 0 0 0 0 0 0]
 [0 2 2 1 1 1 2 0 0 0 0 0 0]
 [0 0 0 2 2 1 0 0 0 0 0 0 0]
 [0 0 2 1 1 1 1 0 0 0 0 0 0]
 [0 0 0 0 0 1 0 2 0 0 0 0 0]
 [0 0 0 0 0 1 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0]]
```














## *ì°¸ê³  LLM êµ¬í˜„

llm ë„¤íŠ¸ì›Œí¬ë¡œ ê°•í™”í•™ìŠµì— í™œìš©í•œ ìµœê·¼ ë…¼ë¬¸(rl)
https://arxiv.org/pdf/2503.21683

ëŒ€êµ­ ë°ì´í„°ê°€ ìˆë‹¤ë©´ vision ëª¨ë¸ì´ ì¶œë ¥í•œ matrixë¥¼ llmì— í”„ë¡¬í”„íŠ¸ë¡œ ì§ì ‘ ë„£ëŠ” ë°©ë²•ë„ ìˆìŒ
í•™ìŠµì€ ëŒ€êµ­ ë°ì´í„°ë¡œ ì…ë ¥í•˜ê³  ì¶œë ¥ì€ ë‹¤ìŒ ì¢Œí‘œë¥¼ ì¶œë ¥í•˜ë„ë¡ í•™ìŠµ

ì•„ë˜ì™€ ê°™ì€ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•´ì•¼í•¨

```prompt
ë‹¤ìŒ ì˜¤ëª© ë©”íŠ¸ë¦­ìŠ¤ë¥¼ ë³´ê³ , ì´ê¸°ê¸° ìœ„í•œ ë‹¤ìŒ ì¢Œí‘œë¥¼ ì˜ˆì¸¡í•˜ì„¸ìš”
ì‚¬ìš©ì :
{board matrix:[[0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,2,1,0,,,,,,,,2,0,0,0,0,0,0,0]]} ì‚¬ìš©ìê°€ ê²€ì€ ëŒì´ê³  agentê°€ í°ëŒì´ì•¼, í°ëŒì´ ë‹¤ìŒì— ë‘˜ ìœ„ì¹˜ë¥¼
agent:
{6,-5}
```







